{
  "test_files": [
    "path/to/document1.pdf",
    "path/to/document2.pdf"
  ],
  "test_cases": [
    {
      "document": "path/to/document1.pdf",
      "query": "What is the main topic of this document?",
      "expected_answer": "The main topic is X",
      "expected_chunks": ["section about X", "introduction to X"]
    },
    {
      "document": "path/to/document1.pdf",
      "query": "What are the key findings?",
      "expected_answer": "The key findings include A, B, and C",
      "expected_chunks": ["results section", "conclusion"]
    }
  ],
  "num_iterations": 5,
  "warmup_iterations": 1,
  "output_dir": "benchmark_results",
  "llm_config": {
    "provider": "openai",
    "model": "gpt-5-mini",
    "temperature": 0.0
  },
  "notes": "This is an example benchmark configuration. Update paths and test cases for your documents."
}
